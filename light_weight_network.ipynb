{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle as sk_shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Lambda, Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Conv2D\n",
    "\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "cropped_pixels = 50 #crop out sections of the image above this pixel positon on the y-axis\n",
    "new_rows  = 11 #number of rows in the resized image\n",
    "new_cols  = 32 #number of columns in the resized image\n",
    "steering_correction = 0.3 #amount of steering wheel angle correction applied to images from the left and the right cameras\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pre_process(line, idx, new_cols, new_rows):\n",
    "    # pre-process each incoming image\n",
    "    source_path = line[idx]\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path = 'data/IMG/' + filename\n",
    "    img = Image.open(current_path)\n",
    "    img = np.array(img)\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)[cropped_pixels:,:,1]  \n",
    "    return cv2.resize(img, (new_cols, new_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['center', 'left', 'right', 'steering', 'throttle', 'brake', 'speed']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load training data from the .csv file\n",
    "lines = []\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "# Pop the first item on the list to get rid of list headers\n",
    "lines.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Training Data Size:  (26463, 11, 32) (26463,)\n",
      "Loading data complete\n"
     ]
    }
   ],
   "source": [
    "# Load X and y values from the training data\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "for line in lines:\n",
    "    # central camera\n",
    "    X.append(pre_process(line, 0, new_cols, new_rows))\n",
    "    y.append(float(line[3]))\n",
    "\n",
    "    # left camera\n",
    "    X.append(pre_process(line, 1, new_cols, new_rows))\n",
    "    y.append(float(line[3]) + steering_correction)\n",
    "\n",
    "    # right camera\n",
    "    X.append(pre_process(line, 2, new_cols, new_rows))\n",
    "    y.append(float(line[3]) - steering_correction)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"Training Data Size: \", X.shape, y.shape)\n",
    "print(\"Loading data complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size:  (52926, 11, 32, 1) (52926,)\n",
      "Loading data complete\n",
      "Flipping and shuffling of data complete\n"
     ]
    }
   ],
   "source": [
    "# flip the image data horizontally and append the new data to the training data\n",
    "X = np.concatenate([X, X[:,:,::-1]])\n",
    "# negate the steering wheel angles of the flipped images\n",
    "y = np.concatenate([y, -y])\n",
    "\n",
    "# shuffle the training data\n",
    "X, y = sk_shuffle(X, y)\n",
    "\n",
    "X_train = X[:,:,:,None]\n",
    "y_train = y[:]\n",
    "\n",
    "print(\"Training Data Size: \", X_train.shape, y_train.shape)\n",
    "print(\"Loading data complete\")\n",
    "print(\"Flipping and shuffling of data complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Network Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "Normalization (Lambda)           (None, 11, 32, 1)     0           lambda_input_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 11, 32, 2)     4           Normalization[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 3, 8, 2)       0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 3, 8, 2)       0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 48)            0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             49          flatten_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 53\n",
      "Trainable params: 53\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model design\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/127.5 - 1., input_shape=(new_rows, new_cols, 1), name='Normalization'))\n",
    "model.add(Conv2D(2, 1, 1, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D((4, 4), (4, 4), 'same'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47633 samples, validate on 5293 samples\n",
      "Epoch 1/25\n",
      "47633/47633 [==============================] - 4s - loss: 0.2630 - val_loss: 0.0720\n",
      "Epoch 2/25\n",
      "47633/47633 [==============================] - 3s - loss: 0.0850 - val_loss: 0.0630\n",
      "Epoch 3/25\n",
      "47633/47633 [==============================] - 3s - loss: 0.0696 - val_loss: 0.0587\n",
      "Epoch 4/25\n",
      "47633/47633 [==============================] - 3s - loss: 0.0657 - val_loss: 0.0559\n",
      "Epoch 5/25\n",
      "47633/47633 [==============================] - 3s - loss: 0.0623 - val_loss: 0.0527\n",
      "Epoch 6/25\n",
      "47633/47633 [==============================] - 3s - loss: 0.0576 - val_loss: 0.0481\n",
      "Epoch 7/25\n",
      "47633/47633 [==============================] - 3s - loss: 0.0515 - val_loss: 0.0426\n",
      "Epoch 8/25\n",
      "47633/47633 [==============================] - 3s - loss: 0.0460 - val_loss: 0.0379\n",
      "Epoch 9/25\n",
      "47633/47633 [==============================] - 3s - loss: 0.0420 - val_loss: 0.0343\n",
      "Epoch 10/25\n",
      "47633/47633 [==============================] - 3s - loss: 0.0396 - val_loss: 0.0319\n",
      "Epoch 11/25\n",
      "47633/47633 [==============================] - 3s - loss: 0.0380 - val_loss: 0.0307\n",
      "Epoch 12/25\n",
      "47633/47633 [==============================] - 3s - loss: 0.0370 - val_loss: 0.0297\n",
      "Epoch 13/25\n",
      "47633/47633 [==============================] - 3s - loss: 0.0367 - val_loss: 0.0295\n",
      "Epoch 14/25\n",
      "47633/47633 [==============================] - 3s - loss: 0.0362 - val_loss: 0.0291\n",
      "Epoch 15/25\n",
      "47633/47633 [==============================] - 3s - loss: 0.0363 - val_loss: 0.0292\n",
      "Epoch 16/25\n",
      "47633/47633 [==============================] - 4s - loss: 0.0358 - val_loss: 0.0291\n",
      "Epoch 17/25\n",
      "47633/47633 [==============================] - 4s - loss: 0.0358 - val_loss: 0.0290\n",
      "Epoch 18/25\n",
      "47633/47633 [==============================] - 4s - loss: 0.0359 - val_loss: 0.0288\n",
      "Epoch 19/25\n",
      "47633/47633 [==============================] - 5s - loss: 0.0358 - val_loss: 0.0291\n",
      "Epoch 20/25\n",
      "47633/47633 [==============================] - 3s - loss: 0.0356 - val_loss: 0.0292\n",
      "Epoch 21/25\n",
      "47633/47633 [==============================] - 3s - loss: 0.0358 - val_loss: 0.0290\n",
      "Epoch 22/25\n",
      "47633/47633 [==============================] - 3s - loss: 0.0356 - val_loss: 0.0285\n",
      "Epoch 23/25\n",
      "47633/47633 [==============================] - 4s - loss: 0.0357 - val_loss: 0.0287\n",
      "Epoch 24/25\n",
      "47633/47633 [==============================] - 4s - loss: 0.0359 - val_loss: 0.0286\n",
      "Epoch 25/25\n",
      "47633/47633 [==============================] - 4s - loss: 0.0357 - val_loss: 0.0286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a1e48d630>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "# Train the model on the training data with 25 epochs\n",
    "model.fit(X_train, y_train, batch_size=batch_size, verbose=1, validation_split=0.1, nb_epoch=25,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# for the new drive.py file\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
